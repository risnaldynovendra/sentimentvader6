{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/datacoding/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/datacoding/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/datacoding/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/datacoding/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"vader_lexicon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullname</th>\n",
       "      <th>Followers</th>\n",
       "      <th>retweets</th>\n",
       "      <th>tweets</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>url</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BilawalBhuttoZardari</td>\n",
       "      <td>5100000</td>\n",
       "      <td>4035</td>\n",
       "      <td>For the first time in the history of Karachi, ...</td>\n",
       "      <td>2023-06-19 15:29:00+00:00</td>\n",
       "      <td>1.670000e+18</td>\n",
       "      <td>https://twitter.com/BBhuttoZardari/status/1670...</td>\n",
       "      <td>@BBhuttoZardari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BilawalBhuttoZardari</td>\n",
       "      <td>5100000</td>\n",
       "      <td>5577</td>\n",
       "      <td>Thanks Swat! üôèüèΩ üôèüèΩ\\nToday, we come together to...</td>\n",
       "      <td>2023-06-17 16:38:00+00:00</td>\n",
       "      <td>1.670000e+18</td>\n",
       "      <td>https://twitter.com/BBhuttoZardari/status/1670...</td>\n",
       "      <td>@BBhuttoZardari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BilawalBhuttoZardari</td>\n",
       "      <td>5100000</td>\n",
       "      <td>4118</td>\n",
       "      <td>My Depest Sympathies With the Families of the ...</td>\n",
       "      <td>2023-06-17 11:09:00+00:00</td>\n",
       "      <td>1.670000e+18</td>\n",
       "      <td>https://twitter.com/BBhuttoZardari/status/1670...</td>\n",
       "      <td>@BBhuttoZardari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BilawalBhuttoZardari</td>\n",
       "      <td>5100000</td>\n",
       "      <td>4757</td>\n",
       "      <td>I thank the Members of Asia Pacific Group at u...</td>\n",
       "      <td>2023-06-22 11:51:00+00:00</td>\n",
       "      <td>1.670000e+18</td>\n",
       "      <td>https://twitter.com/BBhuttoZardari/status/1671...</td>\n",
       "      <td>@BBhuttoZardari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BilawalBhuttoZardari</td>\n",
       "      <td>5100000</td>\n",
       "      <td>4881</td>\n",
       "      <td>Our party has always strived for, and Led the ...</td>\n",
       "      <td>2023-06-16 17:38:00+00:00</td>\n",
       "      <td>1.670000e+18</td>\n",
       "      <td>https://twitter.com/BBhuttoZardari/status/1669...</td>\n",
       "      <td>@BBhuttoZardari</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               fullname  Followers  retweets  \\\n",
       "0  BilawalBhuttoZardari    5100000      4035   \n",
       "1  BilawalBhuttoZardari    5100000      5577   \n",
       "2  BilawalBhuttoZardari    5100000      4118   \n",
       "3  BilawalBhuttoZardari    5100000      4757   \n",
       "4  BilawalBhuttoZardari    5100000      4881   \n",
       "\n",
       "                                              tweets  \\\n",
       "0  For the first time in the history of Karachi, ...   \n",
       "1  Thanks Swat! üôèüèΩ üôèüèΩ\\nToday, we come together to...   \n",
       "2  My Depest Sympathies With the Families of the ...   \n",
       "3  I thank the Members of Asia Pacific Group at u...   \n",
       "4  Our party has always strived for, and Led the ...   \n",
       "\n",
       "                   timestamp      tweet_id  \\\n",
       "0  2023-06-19 15:29:00+00:00  1.670000e+18   \n",
       "1  2023-06-17 16:38:00+00:00  1.670000e+18   \n",
       "2  2023-06-17 11:09:00+00:00  1.670000e+18   \n",
       "3  2023-06-22 11:51:00+00:00  1.670000e+18   \n",
       "4  2023-06-16 17:38:00+00:00  1.670000e+18   \n",
       "\n",
       "                                                 url         username  \n",
       "0  https://twitter.com/BBhuttoZardari/status/1670...  @BBhuttoZardari  \n",
       "1  https://twitter.com/BBhuttoZardari/status/1670...  @BBhuttoZardari  \n",
       "2  https://twitter.com/BBhuttoZardari/status/1670...  @BBhuttoZardari  \n",
       "3  https://twitter.com/BBhuttoZardari/status/1671...  @BBhuttoZardari  \n",
       "4  https://twitter.com/BBhuttoZardari/status/1669...  @BBhuttoZardari  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"combined_data_all_new.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fullname     0\n",
       "Followers    0\n",
       "retweets     0\n",
       "tweets       0\n",
       "timestamp    0\n",
       "tweet_id     0\n",
       "url          0\n",
       "username     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "        text = str(text)\n",
    "        text = re.sub(r'@[A-Za-z0-9]+', '', text)  # remove mentions\n",
    "        text = re.sub(r'#', '', text)  # remove hashtags\n",
    "        text = re.sub(r'RT[\\s]+', '', text)  # remove retweets\n",
    "        text = re.sub(r'https?:\\/\\/\\S+', '', text)  # remove links\n",
    "        text = re.sub(r'[^A-Za-z0-9\\s]+', '', text)  # remove special characters\n",
    "       \n",
    "        return \" \".join(nltk.word_tokenize(text.lower().strip()))\n",
    "\n",
    "df[\"cleaned_tweets\"] = df[\"tweets\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    for the first time in the history of karachi i...\n",
       "1    thanks swat today we come together to maintain...\n",
       "2    my depest sympathies with the families of the ...\n",
       "3    i thank the members of asia pacific group at u...\n",
       "4    our party has always strived for and led the w...\n",
       "Name: cleaned_tweets, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"cleaned_tweets\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for the first time in the history of karachi i congratulate pakistan peoples partys barrister murtaza wahab on mayor karachi and salman abdullah murad on the oath of office it is hoped that the mayor karachi and deputy mayor karachi will deliver the city to new heights of development while serving the people of karachi'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"cleaned_tweets\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(text):\n",
    "        \n",
    "        sid = SentimentIntensityAnalyzer()\n",
    "        sentiment_score = sid.polarity_scores(text)['compound']\n",
    "        sentiment_tag = 'positive' if sentiment_score > 0 else ('negative' if sentiment_score < 0 else 'neutral')\n",
    "        \n",
    "        return sentiment_score, sentiment_tag\n",
    "\n",
    "df['sentiment_score'], df['sentiment_tag'] = zip(*df['cleaned_tweets'].apply(analyze_sentiment))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullname</th>\n",
       "      <th>Followers</th>\n",
       "      <th>retweets</th>\n",
       "      <th>tweets</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>url</th>\n",
       "      <th>username</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BilawalBhuttoZardari</td>\n",
       "      <td>5100000</td>\n",
       "      <td>4035</td>\n",
       "      <td>For the first time in the history of Karachi, ...</td>\n",
       "      <td>2023-06-19 15:29:00+00:00</td>\n",
       "      <td>1.670000e+18</td>\n",
       "      <td>https://twitter.com/BBhuttoZardari/status/1670...</td>\n",
       "      <td>@BBhuttoZardari</td>\n",
       "      <td>for the first time in the history of karachi i...</td>\n",
       "      <td>0.7003</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BilawalBhuttoZardari</td>\n",
       "      <td>5100000</td>\n",
       "      <td>5577</td>\n",
       "      <td>Thanks Swat! üôèüèΩ üôèüèΩ\\nToday, we come together to...</td>\n",
       "      <td>2023-06-17 16:38:00+00:00</td>\n",
       "      <td>1.670000e+18</td>\n",
       "      <td>https://twitter.com/BBhuttoZardari/status/1670...</td>\n",
       "      <td>@BBhuttoZardari</td>\n",
       "      <td>thanks swat today we come together to maintain...</td>\n",
       "      <td>0.9666</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BilawalBhuttoZardari</td>\n",
       "      <td>5100000</td>\n",
       "      <td>4118</td>\n",
       "      <td>My Depest Sympathies With the Families of the ...</td>\n",
       "      <td>2023-06-17 11:09:00+00:00</td>\n",
       "      <td>1.670000e+18</td>\n",
       "      <td>https://twitter.com/BBhuttoZardari/status/1670...</td>\n",
       "      <td>@BBhuttoZardari</td>\n",
       "      <td>my depest sympathies with the families of the ...</td>\n",
       "      <td>-0.8720</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               fullname  Followers  retweets  \\\n",
       "0  BilawalBhuttoZardari    5100000      4035   \n",
       "1  BilawalBhuttoZardari    5100000      5577   \n",
       "2  BilawalBhuttoZardari    5100000      4118   \n",
       "\n",
       "                                              tweets  \\\n",
       "0  For the first time in the history of Karachi, ...   \n",
       "1  Thanks Swat! üôèüèΩ üôèüèΩ\\nToday, we come together to...   \n",
       "2  My Depest Sympathies With the Families of the ...   \n",
       "\n",
       "                   timestamp      tweet_id  \\\n",
       "0  2023-06-19 15:29:00+00:00  1.670000e+18   \n",
       "1  2023-06-17 16:38:00+00:00  1.670000e+18   \n",
       "2  2023-06-17 11:09:00+00:00  1.670000e+18   \n",
       "\n",
       "                                                 url         username  \\\n",
       "0  https://twitter.com/BBhuttoZardari/status/1670...  @BBhuttoZardari   \n",
       "1  https://twitter.com/BBhuttoZardari/status/1670...  @BBhuttoZardari   \n",
       "2  https://twitter.com/BBhuttoZardari/status/1670...  @BBhuttoZardari   \n",
       "\n",
       "                                      cleaned_tweets  sentiment_score  \\\n",
       "0  for the first time in the history of karachi i...           0.7003   \n",
       "1  thanks swat today we come together to maintain...           0.9666   \n",
       "2  my depest sympathies with the families of the ...          -0.8720   \n",
       "\n",
       "  sentiment_tag  \n",
       "0      positive  \n",
       "1      positive  \n",
       "2      negative  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"cleaned_tweets\"]\n",
    "y = df[\"sentiment_tag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have preprocessed data and labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4795    heard with concern about hospitalisation of hi...\n",
       "289     pakistan strongly condemns the insensitive and...\n",
       "2589                                       i am on my way\n",
       "4126    the details of reservations on the amendments ...\n",
       "4494    preparing a cricket ground for the youngsters ...\n",
       "                              ...                        \n",
       "4426    saddened to learn of rahimullah yousafzais pas...\n",
       "466     heartest felications to president xi on which ...\n",
       "3092    from every citizen especially those who will e...\n",
       "3772    after informing the president about the danger...\n",
       "860     renala khurd ki awaam ka faisla puppet pm par ...\n",
       "Name: cleaned_tweets, Length: 3880, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "joblib.dump(vectorizer, \"tf-idf-vectorizer.pkl\")\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the TF-IDF vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(solver=\"lbfgs\")\n",
    "model.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7971163748712667\n"
     ]
    }
   ],
   "source": [
    "#  Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistic_regression_model.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, \"logistic_regression_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Generate a classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Save the model and its results\n",
    "saved_model = {\n",
    "    \"model\": model,\n",
    "    \"vectorizer\": vectorizer,\n",
    "    \"accuracy\": accuracy,\n",
    "    \"classification_report\": class_report\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.76      0.77       335\n",
      "     neutral       0.81      0.80      0.81       208\n",
      "    positive       0.80      0.82      0.81       428\n",
      "\n",
      "    accuracy                           0.80       971\n",
      "   macro avg       0.80      0.79      0.80       971\n",
      "weighted avg       0.80      0.80      0.80       971\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(saved_model, \"logestics_regression_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'LogisticRegression' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m loaded_model \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mlogistic_regression_model.pkl\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[39m# Get the loaded model and vectorizer\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m model \u001b[39m=\u001b[39m loaded_model[\u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m      8\u001b[0m vectorizer \u001b[39m=\u001b[39m loaded_model[\u001b[39m\"\u001b[39m\u001b[39mvectorizer\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     10\u001b[0m \u001b[39m# Get user input\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'LogisticRegression' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# import joblib\n",
    "\n",
    "# # Load the saved model\n",
    "# loaded_model = joblib.load(\"logistic_regression_model.pkl\")\n",
    "\n",
    "# # Get the loaded model and vectorizer\n",
    "# model = loaded_model[\"model\"]\n",
    "# vectorizer = loaded_model[\"vectorizer\"]\n",
    "\n",
    "# # Get user input\n",
    "# user_input = input(\"Enter a tweet: \")\n",
    "\n",
    "# # Preprocess the user input\n",
    "# cleaned_input = clean_text(user_input)  # You need to define preprocess_text function\n",
    "\n",
    "# # Vectorize the preprocessed input\n",
    "# input_vector = vectorizer.transform([cleaned_input])\n",
    "\n",
    "# # Make a prediction\n",
    "# prediction = model.predict(input_vector)\n",
    "\n",
    "# # Print the sentiment prediction\n",
    "# print(\"Predicted Sentiment:\", prediction[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def map_to_sentiment_label(predicted_sentiment):\n",
    "#     if predicted_sentiment > 0:  # Assuming 1 represents positive sentiment, adjust as needed\n",
    "#         return \"positive\"\n",
    "#     elif predicted_sentiment < 0:  # Assuming 0 represents neutral sentiment, adjust as needed\n",
    "#         return \"negative\"\n",
    "#     else:  # Assuming -1 represents negative sentiment, adjust as needed\n",
    "#         return \"neutral\"\n",
    "\n",
    "# # Example usage:\n",
    "# # predicted_sentiment = 1  # Replace with the actual predicted sentiment value\n",
    "# # predicted_sentiment_label = map_to_sentiment_label(predicted_sentiment)\n",
    "# # print(f\"Predicted Sentiment: {predicted_sentiment_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "\n",
    "# # Load the logistic regression model\n",
    "# loaded_model = joblib.load(\"logistic_regression_model.pkl\")\n",
    "\n",
    "# # Get user input\n",
    "# user_input = \"Some text you want to classify\"\n",
    "\n",
    "# # Preprocess user input (use the same preprocessing used during training)\n",
    "# preprocessed_input = clean_text(user_input)\n",
    "\n",
    "# # Vectorize the preprocessed input using the same vectorizer used during training\n",
    "# input_vector = vectorizer.transform([preprocessed_input])\n",
    "\n",
    "# # Predict the sentiment using the loaded logistic regression model\n",
    "# predicted_sentiment = loaded_model.predict(input_vector)\n",
    "\n",
    "# # Map the predicted sentiment to the appropriate label (e.g., \"positive\", \"negative\")\n",
    "# predicted_sentiment_label = map_to_sentiment_label(predicted_sentiment)\n",
    "\n",
    "# # Print or use the predicted sentiment label as needed\n",
    "# print(f\"Predicted Sentiment: {predicted_sentiment_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.8053553038105047\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create an SVM model\n",
    "svm_model = SVC(kernel='linear')\n",
    "\n",
    "# Train the SVM model\n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "svm_predictions = svm_model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "\n",
    "print(\"SVM Accuracy:\", svm_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm_model.pkl']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the SVM model to a .pkl file\n",
    "model_filename = 'svm_model.pkl'\n",
    "joblib.dump(svm_model, model_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the SVM model from the .pkl file\n",
    "loaded_model = joblib.load(model_filename)\n",
    "\n",
    "# Now you can use loaded_model for predictions\n",
    "svm_predictions = loaded_model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'neutral', 'negative', 'negative', 'negative',\n",
       "       'negative', 'negative', 'neutral', 'positive', 'negative',\n",
       "       'negative', 'negative', 'neutral', 'negative', 'negative',\n",
       "       'positive', 'negative', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'positive', 'positive', 'positive', 'neutral', 'negative',\n",
       "       'neutral', 'neutral', 'positive', 'positive', 'positive',\n",
       "       'negative', 'negative', 'neutral', 'neutral', 'negative',\n",
       "       'neutral', 'neutral', 'positive', 'neutral', 'negative',\n",
       "       'positive', 'negative', 'neutral', 'positive', 'neutral',\n",
       "       'negative', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'negative',\n",
       "       'positive', 'neutral', 'positive', 'neutral', 'negative',\n",
       "       'neutral', 'neutral', 'negative', 'negative', 'negative',\n",
       "       'neutral', 'positive', 'negative', 'negative', 'neutral',\n",
       "       'positive', 'negative', 'positive', 'negative', 'positive',\n",
       "       'neutral', 'positive', 'neutral', 'negative', 'positive',\n",
       "       'positive', 'neutral', 'negative', 'positive', 'positive',\n",
       "       'positive', 'negative', 'negative', 'negative', 'negative',\n",
       "       'positive', 'negative', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'negative', 'positive', 'neutral', 'negative',\n",
       "       'negative', 'negative', 'positive', 'negative', 'neutral',\n",
       "       'neutral', 'neutral', 'positive', 'positive', 'neutral',\n",
       "       'positive', 'positive', 'negative', 'negative', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'negative', 'positive', 'positive', 'neutral',\n",
       "       'positive', 'positive', 'negative', 'positive', 'negative',\n",
       "       'neutral', 'positive', 'negative', 'neutral', 'negative',\n",
       "       'positive', 'positive', 'positive', 'negative', 'negative',\n",
       "       'positive', 'positive', 'neutral', 'positive', 'negative',\n",
       "       'positive', 'negative', 'negative', 'negative', 'negative',\n",
       "       'positive', 'neutral', 'positive', 'positive', 'negative',\n",
       "       'neutral', 'neutral', 'positive', 'positive', 'neutral',\n",
       "       'positive', 'positive', 'negative', 'negative', 'positive',\n",
       "       'negative', 'negative', 'positive', 'negative', 'positive',\n",
       "       'neutral', 'positive', 'neutral', 'negative', 'negative',\n",
       "       'positive', 'neutral', 'neutral', 'positive', 'negative',\n",
       "       'negative', 'negative', 'positive', 'negative', 'positive',\n",
       "       'negative', 'positive', 'positive', 'neutral', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'neutral', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'neutral', 'positive', 'neutral', 'neutral',\n",
       "       'negative', 'neutral', 'positive', 'negative', 'positive',\n",
       "       'negative', 'negative', 'neutral', 'negative', 'positive',\n",
       "       'neutral', 'negative', 'positive', 'negative', 'positive',\n",
       "       'positive', 'positive', 'positive', 'neutral', 'neutral',\n",
       "       'negative', 'negative', 'negative', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'neutral',\n",
       "       'negative', 'positive', 'positive', 'positive', 'negative',\n",
       "       'negative', 'positive', 'negative', 'neutral', 'neutral',\n",
       "       'positive', 'neutral', 'positive', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'negative', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'neutral',\n",
       "       'positive', 'neutral', 'negative', 'neutral', 'positive',\n",
       "       'negative', 'positive', 'negative', 'negative', 'neutral',\n",
       "       'negative', 'positive', 'positive', 'negative', 'negative',\n",
       "       'positive', 'neutral', 'positive', 'negative', 'negative',\n",
       "       'positive', 'positive', 'negative', 'neutral', 'negative',\n",
       "       'positive', 'negative', 'negative', 'neutral', 'positive',\n",
       "       'neutral', 'neutral', 'positive', 'neutral', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'negative',\n",
       "       'positive', 'positive', 'negative', 'positive', 'positive',\n",
       "       'negative', 'positive', 'negative', 'negative', 'neutral',\n",
       "       'negative', 'neutral', 'positive', 'neutral', 'negative',\n",
       "       'positive', 'positive', 'negative', 'positive', 'negative',\n",
       "       'neutral', 'positive', 'negative', 'positive', 'negative',\n",
       "       'negative', 'positive', 'neutral', 'positive', 'neutral',\n",
       "       'positive', 'negative', 'negative', 'positive', 'positive',\n",
       "       'positive', 'negative', 'negative', 'negative', 'positive',\n",
       "       'positive', 'neutral', 'positive', 'negative', 'positive',\n",
       "       'negative', 'negative', 'neutral', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'neutral', 'positive',\n",
       "       'positive', 'positive', 'negative', 'negative', 'negative',\n",
       "       'positive', 'neutral', 'positive', 'positive', 'neutral',\n",
       "       'neutral', 'negative', 'positive', 'negative', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'neutral',\n",
       "       'negative', 'negative', 'negative', 'negative', 'negative',\n",
       "       'positive', 'neutral', 'negative', 'positive', 'positive',\n",
       "       'negative', 'positive', 'negative', 'neutral', 'negative',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'negative', 'negative', 'negative', 'neutral', 'negative',\n",
       "       'positive', 'negative', 'neutral', 'positive', 'positive',\n",
       "       'negative', 'positive', 'negative', 'positive', 'negative',\n",
       "       'neutral', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'neutral', 'neutral', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'neutral',\n",
       "       'positive', 'positive', 'positive', 'negative', 'neutral',\n",
       "       'positive', 'neutral', 'negative', 'positive', 'positive',\n",
       "       'neutral', 'negative', 'positive', 'negative', 'positive',\n",
       "       'negative', 'positive', 'positive', 'negative', 'positive',\n",
       "       'negative', 'neutral', 'positive', 'neutral', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'neutral', 'positive', 'positive', 'neutral', 'negative',\n",
       "       'neutral', 'neutral', 'negative', 'positive', 'negative',\n",
       "       'negative', 'positive', 'negative', 'negative', 'positive',\n",
       "       'neutral', 'negative', 'neutral', 'positive', 'neutral', 'neutral',\n",
       "       'positive', 'positive', 'negative', 'positive', 'positive',\n",
       "       'negative', 'negative', 'negative', 'neutral', 'negative',\n",
       "       'positive', 'neutral', 'negative', 'neutral', 'positive',\n",
       "       'neutral', 'positive', 'positive', 'negative', 'negative',\n",
       "       'neutral', 'positive', 'negative', 'positive', 'negative',\n",
       "       'positive', 'neutral', 'positive', 'neutral', 'neutral',\n",
       "       'positive', 'positive', 'neutral', 'positive', 'neutral',\n",
       "       'neutral', 'neutral', 'positive', 'negative', 'positive',\n",
       "       'positive', 'positive', 'negative', 'negative', 'positive',\n",
       "       'negative', 'negative', 'negative', 'positive', 'negative',\n",
       "       'neutral', 'positive', 'negative', 'neutral', 'negative',\n",
       "       'positive', 'negative', 'negative', 'positive', 'positive',\n",
       "       'negative', 'neutral', 'positive', 'negative', 'negative',\n",
       "       'negative', 'negative', 'positive', 'neutral', 'negative',\n",
       "       'positive', 'positive', 'negative', 'negative', 'positive',\n",
       "       'neutral', 'negative', 'negative', 'negative', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'neutral',\n",
       "       'neutral', 'positive', 'negative', 'negative', 'negative',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'negative', 'neutral', 'negative', 'positive', 'positive',\n",
       "       'negative', 'neutral', 'neutral', 'negative', 'neutral',\n",
       "       'positive', 'positive', 'negative', 'neutral', 'negative',\n",
       "       'positive', 'positive', 'negative', 'negative', 'positive',\n",
       "       'negative', 'positive', 'negative', 'negative', 'neutral',\n",
       "       'positive', 'positive', 'positive', 'negative', 'neutral',\n",
       "       'negative', 'positive', 'negative', 'positive', 'neutral',\n",
       "       'negative', 'negative', 'neutral', 'positive', 'neutral',\n",
       "       'positive', 'positive', 'neutral', 'neutral', 'neutral',\n",
       "       'negative', 'positive', 'positive', 'negative', 'negative',\n",
       "       'neutral', 'positive', 'positive', 'negative', 'negative',\n",
       "       'positive', 'positive', 'positive', 'neutral', 'positive',\n",
       "       'neutral', 'negative', 'positive', 'neutral', 'negative',\n",
       "       'positive', 'negative', 'positive', 'negative', 'neutral',\n",
       "       'positive', 'positive', 'positive', 'negative', 'negative',\n",
       "       'positive', 'neutral', 'negative', 'positive', 'negative',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'negative', 'positive', 'negative',\n",
       "       'neutral', 'neutral', 'positive', 'negative', 'negative',\n",
       "       'neutral', 'negative', 'negative', 'negative', 'positive',\n",
       "       'negative', 'positive', 'negative', 'negative', 'positive',\n",
       "       'neutral', 'negative', 'negative', 'neutral', 'neutral',\n",
       "       'negative', 'positive', 'positive', 'neutral', 'negative',\n",
       "       'positive', 'negative', 'negative', 'negative', 'negative',\n",
       "       'negative', 'positive', 'neutral', 'positive', 'negative',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'neutral', 'negative', 'positive', 'positive',\n",
       "       'neutral', 'positive', 'negative', 'neutral', 'negative',\n",
       "       'positive', 'neutral', 'negative', 'negative', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'neutral',\n",
       "       'negative', 'positive', 'negative', 'neutral', 'neutral',\n",
       "       'negative', 'negative', 'neutral', 'positive', 'neutral',\n",
       "       'positive', 'positive', 'negative', 'positive', 'negative',\n",
       "       'positive', 'neutral', 'neutral', 'negative', 'neutral',\n",
       "       'positive', 'neutral', 'positive', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'negative', 'negative', 'positive', 'positive',\n",
       "       'neutral', 'positive', 'positive', 'positive', 'neutral',\n",
       "       'negative', 'negative', 'negative', 'positive', 'positive',\n",
       "       'positive', 'negative', 'negative', 'negative', 'neutral',\n",
       "       'positive', 'positive', 'positive', 'negative', 'neutral',\n",
       "       'neutral', 'negative', 'neutral', 'negative', 'negative',\n",
       "       'negative', 'positive', 'negative', 'neutral', 'neutral',\n",
       "       'negative', 'neutral', 'positive', 'positive', 'negative',\n",
       "       'negative', 'negative', 'positive', 'positive', 'negative',\n",
       "       'positive', 'negative', 'negative', 'negative', 'positive',\n",
       "       'negative', 'negative', 'negative', 'positive', 'negative',\n",
       "       'neutral', 'neutral', 'positive', 'negative', 'positive',\n",
       "       'negative', 'neutral', 'neutral', 'negative', 'positive',\n",
       "       'positive', 'negative', 'negative', 'positive', 'neutral',\n",
       "       'negative', 'negative', 'positive', 'positive', 'positive',\n",
       "       'neutral', 'positive', 'neutral', 'positive', 'neutral',\n",
       "       'negative', 'negative', 'negative', 'negative', 'positive',\n",
       "       'negative', 'positive', 'negative', 'positive', 'negative',\n",
       "       'positive', 'negative', 'negative', 'negative', 'negative',\n",
       "       'positive', 'positive', 'negative', 'positive', 'neutral',\n",
       "       'neutral', 'positive', 'positive', 'negative', 'neutral',\n",
       "       'neutral', 'neutral', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'negative',\n",
       "       'negative', 'negative', 'neutral', 'positive', 'negative',\n",
       "       'neutral', 'positive', 'positive', 'negative', 'neutral',\n",
       "       'negative', 'neutral', 'negative', 'positive', 'positive',\n",
       "       'positive', 'negative', 'neutral', 'negative', 'positive',\n",
       "       'neutral', 'neutral', 'positive', 'neutral', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'negative',\n",
       "       'neutral', 'neutral', 'positive', 'positive', 'positive',\n",
       "       'positive', 'neutral', 'neutral', 'negative', 'neutral',\n",
       "       'positive', 'positive', 'negative', 'negative', 'positive',\n",
       "       'positive', 'positive', 'negative', 'neutral', 'negative',\n",
       "       'neutral', 'negative', 'neutral', 'negative', 'negative',\n",
       "       'neutral', 'positive', 'positive', 'negative', 'positive',\n",
       "       'negative', 'positive', 'neutral', 'negative', 'negative',\n",
       "       'neutral', 'neutral', 'positive', 'negative', 'positive',\n",
       "       'negative', 'positive', 'neutral', 'positive', 'positive',\n",
       "       'negative', 'negative', 'neutral', 'positive', 'negative',\n",
       "       'positive', 'neutral', 'positive', 'positive', 'positive'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# # Create a list of models\n",
    "# models = [('logreg', logistic_regression_model), ('svm', svm_model), ('rf', random_forest_model)]\n",
    "\n",
    "# # Create a VotingClassifier\n",
    "# voting_classifier = VotingClassifier(estimators=models, voting='hard')\n",
    "\n",
    "# # Train the VotingClassifier\n",
    "# voting_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# # Make predictions using the VotingClassifier\n",
    "# ensemble_predictions = voting_classifier.predict(X_test_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # Define a range of hyperparameters to search\n",
    "# param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2']}\n",
    "\n",
    "# # Create a grid search object\n",
    "# grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "\n",
    "# # Fit the grid search to your data\n",
    "# grid_search.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# # Get the best hyperparameters\n",
    "# best_params = grid_search.best_params_\n",
    "# print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# from scipy.stats import uniform\n",
    "\n",
    "# # Define a distribution over hyperparameters\n",
    "# param_dist = {'C': uniform(0.001, 100), 'penalty': ['l1', 'l2']}\n",
    "\n",
    "# # Create a random search object\n",
    "# random_search = RandomizedSearchCV(LogisticRegression(), param_distributions=param_dist, n_iter=100, cv=5)\n",
    "\n",
    "# # Fit the random search to your data\n",
    "# random_search.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# # Get the best hyperparameters\n",
    "# best_params = random_search.best_params_\n",
    "# print(\"Best Hyperparameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the output on the user input text\n",
    "# user_input = input(\"enter text: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
